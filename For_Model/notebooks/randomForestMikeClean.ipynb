{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns #visualisation\n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "from sklearn.preprocessing import OneHotEncoder, scale, StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, average_precision_score,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Bidirectional, LSTM, Reshape,TimeDistributed, GRU, concatenate, add,Input\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df_training = pd.read_csv(\"training_set_features.csv\")\n",
    "df_labels = pd.read_csv(\"training_set_labels.csv\")\n",
    "df = df_labels.merge(df_training, on = \"respondent_id\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean feature and label dataset\n",
    "df1 = df.drop([\"health_insurance\",\"employment_industry\", \"employment_occupation\"], axis=1)\n",
    "df2 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean label dataset\n",
    "df_y = df2.select_dtypes(include=['int64'])\n",
    "df_y = df_y[[\"respondent_id\",\"h1n1_vaccine\"]]\n",
    "df_y = np.array(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep original features to the side \n",
    "df_original_features = df2.drop([\"h1n1_vaccine\", \"seasonal_vaccine\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean features dataset\n",
    "\n",
    "# drop label columns\n",
    "df_x = df2.drop([\"h1n1_vaccine\", \"seasonal_vaccine\"], axis=1)\n",
    "\n",
    "# pull out respondent id, categorical string, and categorical number features\n",
    "df_int = df_x.select_dtypes(include=[\"int64\"])\n",
    "df_categories = df_x.select_dtypes(include=['object'])\n",
    "df_float = df_x.select_dtypes(include=['float64'])\n",
    "\n",
    "# turn the above df's into arrays\n",
    "int_array = np.array(df_int)\n",
    "features_array = np.array(df_categories)\n",
    "float_array = np.array(df_float)\n",
    "\n",
    "# transform categorical strings into one hot encoded array\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "onehot = encoder.fit_transform(features_array)\n",
    "\n",
    "# scale the features\n",
    "df_features = np.concatenate((float_array, onehot),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 1.],\n",
       "       [3., 2., 0., ..., 1., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [2., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 2., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df_features = min_max_scaler.fit_transform(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the respondent id back to the scale feature array\n",
    "df_features = np.concatenate((int_array,df_features),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 3.33333333e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.00000000e+00, 3.33333333e-01, 5.00000000e-01, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [2.67020000e+04, 6.66666667e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [2.67030000e+04, 3.33333333e-01, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [2.67060000e+04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels into training and test sets\n",
    "X_train_master, X_test_master, y_train_master, y_test_master = train_test_split(df_features, df_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14761,     0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_master[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.47610000e+04, 3.33333333e-01, 1.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.50000000e-01,\n",
       "       2.50000000e-01, 2.50000000e-01, 2.50000000e-01, 2.50000000e-01,\n",
       "       2.50000000e-01, 0.00000000e+00, 3.33333333e-01, 1.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.00000000e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_master[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.34500000e+03, 6.66666667e-01, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [2.51590000e+04, 3.33333333e-01, 5.00000000e-01, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.17780000e+04, 3.33333333e-01, 5.00000000e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       ...,\n",
       "       [7.32700000e+03, 0.00000000e+00, 5.00000000e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.15400000e+03, 6.66666667e-01, 1.00000000e+00, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.15010000e+04, 0.00000000e+00, 5.00000000e-01, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove training labels for model fitting purposes\n",
    "X_train = X_train_master[:,1:]\n",
    "X_test = X_test_master[:,1:]\n",
    "y_train = np.ravel(y_train_master[:,1:])\n",
    "y_test = np.ravel(y_test_master[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8226430462227652\n",
      "... Done ...\n"
     ]
    }
   ],
   "source": [
    "#Define Model Instances\n",
    "model_optimal = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "\n",
    "#Fit Model\n",
    "model_optimal.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "y_model = model_optimal.predict(X_test)\n",
    "\n",
    "#get accuracy score\n",
    "print(accuracy_score(y_test, y_model))\n",
    "# #Save Model\n",
    "# filename = '../models/randomForestML.sav'\n",
    "# joblib.dump(model_optimal, filename)\n",
    "\n",
    "print(\"... Done ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
